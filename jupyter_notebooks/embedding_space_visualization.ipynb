{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Checkpoint Embedding Space Visualization\n",
    "\n",
    "This notebook extracts **768-dimensional embeddings** (right before the contrastive probing layer) from 4 different finetuned checkpoints using the **same validation dataset** across all models.\n",
    "\n",
    "## Architecture Reminder\n",
    "```\n",
    "Input (96³) → Encoder → Features (768-dim, spatial) → Global Pool → 768-dim vector\n",
    "                                                                         ↓\n",
    "                                                            Projection MLP (Probing Layer)\n",
    "                                                                         ↓\n",
    "                                                                    128-dim embedding\n",
    "```\n",
    "\n",
    "**We extract at the 768-dim stage** (after encoder + pooling, before projection MLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import sys\nsys.path.append('/home/mgazda/Projects/UMBRA')\n\nimport numpy as np\nimport torch\nimport torch.nn.functional as F\nfrom pathlib import Path\nfrom typing import Dict, List, Tuple\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.manifold import TSNE\nfrom sklearn.decomposition import PCA\nimport pandas as pd\nimport re\n\n# Import your models\nfrom models.foundation import ContrastiveMAEPretrainer\nfrom models.finetuning import FinetuningModule\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(f\"Using device: {device}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration: Your 4 Checkpoints\n",
    "\n",
    "**IMPORTANT**: Update these paths to point to your actual checkpoint files!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Define your 4 checkpoint paths and their labels\nCHECKPOINTS = {\n    'MCL': '/home/mg873uh/data/Petros/ckpts/contrastive_modality-step=200000.ckpt',\n    'CL': '/home/mg873uh/data/Petros/ckpts/contrastive_regular-step=200000.ckpt',\n    'MAE + MCL': '/home/mg873uh/data/Petros/ckpts/combined_modality-step=200000.ckpt',\n    'MAE + CL': '/home/mg873uh/data/Petros/ckpts/combined_regular-step=200000.ckpt',\n}\n\n# Validation dataset configuration (PRETRAIN data directory)\nVAL_DATA_DIR = '/home/mg873uh/Projects_kb/data/pretrain_parsed'\nSEED = 42  # Same seed used during pretraining to ensure same validation split\nINPUT_SIZE = 96  # Input volume size (96x96x96)\n\n# Output directory for embeddings\nOUTPUT_DIR = Path('/home/mgazda/Projects/UMBRA/embeddings_analysis')\nOUTPUT_DIR.mkdir(exist_ok=True, parents=True)\n\nprint(f\"Output directory: {OUTPUT_DIR}\")\nprint(f\"\\nCheckpoints to process:\")\nfor name, path in CHECKPOINTS.items():\n    print(f\"  {name}: {path}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Validation Dataset Loading (PRETRAIN)\n\nLoad the validation dataset using **ContrastiveDataModule** - the **exact same configuration** as during pretraining to ensure consistency.\n\n**Key Points:**\n- Uses flat file structure: `sub_{patient}_ses_{session}_{modality}.npy`\n- 98% train / 2% validation split (same as pretraining)\n- Excludes `scan_*` files by default (ignore_scan_label=True)\n- Same seed = same validation patients across all checkpoints"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "from data.contrastive_datamodule import ContrastiveDataModule\nfrom data.transforms import get_contrastive_transforms\n\n# Create validation transforms (no augmentation)\n# Use conservative mode and val_mode for validation\nval_transforms = get_contrastive_transforms(\n    keys=(\"vol1\", \"vol2\"),  # Contrastive pairs\n    input_size=INPUT_SIZE,\n    conservative_mode=True,  # Minimal augmentation\n    val_mode=True,  # No augmentation for validation\n    recon=False,  # Not needed for embedding extraction\n)\n\n# Create PRETRAIN data module with the same configuration as during pretraining\ndata_module = ContrastiveDataModule(\n    data_dir=VAL_DATA_DIR,\n    train_transforms=val_transforms,  # Not used for validation\n    val_transforms=val_transforms,\n    contrastive_mode=\"modality_pairs\",  # or \"regular\" - doesn't matter for validation\n    input_size=INPUT_SIZE,\n    batch_size=1,  # Process one sample at a time for embedding extraction\n    num_workers=0,\n    seed=SEED,  # Critical: same seed as pretraining!\n)\n\n# Setup the data module\ndata_module.setup('fit')\n\n# Get validation dataloader\nval_loader = data_module.val_dataloader()\n\nprint(f\"Validation dataset size: {len(val_loader.dataset)} samples\")\nprint(f\"Validation split: 98% train / 2% validation\")\nprint(f\"Validation split seed: {SEED}\")\nprint(f\"Data directory: {VAL_DATA_DIR}\")\nprint(f\"\\nData structure expected:\")\nprint(f\"  {VAL_DATA_DIR}/\")\nprint(f\"    sub_XXX/\")\nprint(f\"      ses_YYY/\")\nprint(f\"        t1.npy, flair.npy, dwi.npy, etc.\")\nprint(f\"\\nNote: 'scan_*' files are automatically excluded (ignore_scan_label=True by default)\")\nprint(f\"This validation set is FIXED across all 4 checkpoints (same as used during pretraining)\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding Extraction Function\n",
    "\n",
    "Extract **768-dim embeddings** right before the contrastive probing layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def extract_embeddings_before_probing(\n    model: torch.nn.Module,\n    dataloader: torch.utils.data.DataLoader,\n    device: torch.device,\n) -> Tuple[np.ndarray, List[str], List[str], List[str], List[str]]:\n    \"\"\"\n    Extract 768-dim embeddings from encoder (before contrastive probing layer).\n    \n    Args:\n        model: Loaded checkpoint model\n        dataloader: Validation dataloader (from ContrastiveDataModule)\n        device: Device to run on\n    \n    Returns:\n        embeddings: (N, 768) array of embeddings\n        labels: List of modality names (from filename)\n        patient_ids: List of patient IDs\n        session_ids: List of session IDs\n        metadata: List of sample identifiers\n    \"\"\"\n    model = model.to(device)\n    model.eval()\n    \n    all_embeddings = []\n    all_labels = []\n    all_patient_ids = []\n    all_session_ids = []\n    all_metadata = []\n    \n    with torch.no_grad():\n        for batch_idx, batch in enumerate(tqdm(dataloader, desc='Extracting embeddings')):\n            # ContrastiveDataModule returns dict with 'vol1', 'vol2', 'patient', 'session'\n            if isinstance(batch, dict):\n                # Use vol1 for embedding extraction\n                volume = batch['vol1'].to(device)\n                \n                # Extract patient and session IDs from ContrastivePatientDataset\n                patient_id = batch.get('patient', f'unknown_{batch_idx}')\n                session_id = batch.get('session', 'unknown')\n                \n                # Convert to string if tensor\n                if torch.is_tensor(patient_id):\n                    patient_id = str(patient_id.item())\n                if torch.is_tensor(session_id):\n                    session_id = str(session_id.item())\n                \n                all_patient_ids.append(patient_id)\n                all_session_ids.append(session_id)\n                \n                # Extract modality from path if available\n                path1 = batch.get('path1', '')\n                if path1:\n                    # Extract modality from filename (e.g., /path/to/sub_1/ses_1/t1.npy -> t1)\n                    modality = Path(path1).stem if isinstance(path1, str) else 'unknown'\n                    # Remove numeric suffixes like t1_2 -> t1\n                    modality = re.sub(r'_\\d+$', '', modality)\n                else:\n                    modality = 'unknown'\n                all_labels.append(modality)\n            else:\n                # Fallback for unexpected format\n                volume = batch[0].to(device) if isinstance(batch, (list, tuple)) else batch.to(device)\n                all_labels.append('unknown')\n                all_patient_ids.append(f'unknown_{batch_idx}')\n                all_session_ids.append('unknown')\n            \n            # Extract features from encoder (last layer output)\n            # For ContrastiveMAEPretrainer\n            if hasattr(model, 'encoder'):\n                features = model.encoder(volume)[-1]  # (B, 768, D, H, W)\n            elif hasattr(model, 'model') and hasattr(model.model, 'encoder'):\n                features = model.model.encoder(volume)[-1]  # For FinetuningModule\n            else:\n                raise AttributeError(\"Model does not have expected encoder structure\")\n            \n            # Apply global average pooling (same as first step of projection head)\n            features_pooled = F.adaptive_avg_pool3d(features, 1)  # (B, 768, 1, 1, 1)\n            features_pooled = features_pooled.flatten(1)  # (B, 768)\n            \n            # Convert to numpy\n            embedding = features_pooled.cpu().numpy()\n            all_embeddings.append(embedding)\n            all_metadata.append(f'{patient_id}_ses_{session_id}_{modality}')\n    \n    # Concatenate all embeddings\n    embeddings = np.concatenate(all_embeddings, axis=0)\n    \n    print(f\"Extracted {len(embeddings)} embeddings with shape {embeddings.shape}\")\n    print(f\"Unique patients: {len(set(all_patient_ids))}\")\n    print(f\"Modalities found: {set(all_labels)}\")\n    \n    return embeddings, all_labels, all_patient_ids, all_session_ids, all_metadata"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Embeddings from All 4 Checkpoints\n",
    "\n",
    "Process each checkpoint and save embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Dictionary to store all embeddings\nall_checkpoint_embeddings = {}\n\nfor checkpoint_name, checkpoint_path in CHECKPOINTS.items():\n    print(f\"\\n{'='*80}\")\n    print(f\"Processing: {checkpoint_name}\")\n    print(f\"Checkpoint: {checkpoint_path}\")\n    print(f\"{'='*80}\")\n    \n    # Check if checkpoint exists\n    if not Path(checkpoint_path).exists():\n        print(f\"WARNING: Checkpoint not found at {checkpoint_path}\")\n        print(\"Skipping...\")\n        continue\n    \n    try:\n        # Try loading as FinetuningModule first (most likely)\n        try:\n            model = FinetuningModule.load_from_checkpoint(checkpoint_path)\n            print(\"Loaded as FinetuningModule\")\n        except Exception as e1:\n            # Try loading as ContrastiveMAEPretrainer\n            try:\n                model = ContrastiveMAEPretrainer.load_from_checkpoint(checkpoint_path)\n                print(\"Loaded as ContrastiveMAEPretrainer\")\n            except Exception as e2:\n                print(f\"Failed to load checkpoint:\")\n                print(f\"  As FinetuningModule: {e1}\")\n                print(f\"  As ContrastiveMAEPretrainer: {e2}\")\n                continue\n        \n        # Extract embeddings with patient IDs\n        embeddings, labels, patient_ids, session_ids, metadata = extract_embeddings_before_probing(\n            model=model,\n            dataloader=val_loader,\n            device=device,\n        )\n        \n        # Store results\n        all_checkpoint_embeddings[checkpoint_name] = {\n            'embeddings': embeddings,\n            'labels': labels,\n            'patient_ids': patient_ids,\n            'session_ids': session_ids,\n            'metadata': metadata,\n        }\n        \n        # Save individual checkpoint embeddings\n        save_path = OUTPUT_DIR / f\"embeddings_{checkpoint_name.replace(' ', '_').lower()}.npz\"\n        np.savez(\n            save_path,\n            embeddings=embeddings,\n            labels=np.array(labels),\n            patient_ids=np.array(patient_ids),\n            session_ids=np.array(session_ids),\n            metadata=np.array(metadata),\n        )\n        print(f\"\\nSaved embeddings to: {save_path}\")\n        \n        # Clean up GPU memory\n        del model\n        torch.cuda.empty_cache()\n        \n    except Exception as e:\n        print(f\"Error processing {checkpoint_name}: {e}\")\n        import traceback\n        traceback.print_exc()\n        continue\n\nprint(f\"\\n{'='*80}\")\nprint(f\"Extraction complete!\")\nprint(f\"Processed {len(all_checkpoint_embeddings)} checkpoints\")\nprint(f\"Results saved to: {OUTPUT_DIR}\")\nprint(f\"{'='*80}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"EMBEDDING EXTRACTION SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for checkpoint_name, data in all_checkpoint_embeddings.items():\n",
    "    embeddings = data['embeddings']\n",
    "    labels = data['labels']\n",
    "    \n",
    "    print(f\"\\n{checkpoint_name}:\")\n",
    "    print(f\"  Shape: {embeddings.shape}\")\n",
    "    print(f\"  Mean norm: {np.linalg.norm(embeddings, axis=1).mean():.4f}\")\n",
    "    print(f\"  Std norm: {np.linalg.norm(embeddings, axis=1).std():.4f}\")\n",
    "    \n",
    "    # Label distribution\n",
    "    from collections import Counter\n",
    "    label_counts = Counter(labels)\n",
    "    print(f\"  Label distribution:\")\n",
    "    for label, count in label_counts.items():\n",
    "        print(f\"    {label}: {count}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization: PCA Comparison Across Checkpoints\n",
    "\n",
    "Visualize how the embedding spaces differ across the 4 checkpoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IEEE publication style\n",
    "plt.rcParams.update({\n",
    "    'font.family': 'serif',\n",
    "    'font.size': 10,\n",
    "    'figure.dpi': 100,\n",
    "    'savefig.dpi': 300,\n",
    "})\n",
    "\n",
    "# Create subplots for each checkpoint\n",
    "n_checkpoints = len(all_checkpoint_embeddings)\n",
    "fig, axes = plt.subplots(1, n_checkpoints, figsize=(5*n_checkpoints, 5))\n",
    "\n",
    "if n_checkpoints == 1:\n",
    "    axes = [axes]\n",
    "\n",
    "for idx, (checkpoint_name, data) in enumerate(all_checkpoint_embeddings.items()):\n",
    "    ax = axes[idx]\n",
    "    \n",
    "    embeddings = data['embeddings']\n",
    "    labels = data['labels']\n",
    "    \n",
    "    # Apply PCA\n",
    "    pca = PCA(n_components=2, random_state=42)\n",
    "    embeddings_2d = pca.fit_transform(embeddings)\n",
    "    \n",
    "    # Plot\n",
    "    unique_labels = sorted(list(set(labels)))\n",
    "    colors = plt.cm.tab10(np.linspace(0, 1, len(unique_labels)))\n",
    "    \n",
    "    for label_idx, label in enumerate(unique_labels):\n",
    "        mask = np.array(labels) == label\n",
    "        ax.scatter(\n",
    "            embeddings_2d[mask, 0],\n",
    "            embeddings_2d[mask, 1],\n",
    "            c=[colors[label_idx]],\n",
    "            label=label,\n",
    "            alpha=0.6,\n",
    "            s=30,\n",
    "            edgecolors='black',\n",
    "            linewidth=0.5,\n",
    "        )\n",
    "    \n",
    "    ax.set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]*100:.1f}%)')\n",
    "    ax.set_ylabel(f'PC2 ({pca.explained_variance_ratio_[1]*100:.1f}%)')\n",
    "    ax.set_title(f'{checkpoint_name}\\n(768-dim embeddings)', fontweight='bold')\n",
    "    ax.legend(loc='best', fontsize=8)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "save_path = OUTPUT_DIR / 'pca_comparison_all_checkpoints.png'\n",
    "plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "print(f\"Saved PCA comparison to: {save_path}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization: t-SNE Comparison (Optional, slower)\n",
    "\n",
    "Run t-SNE for more detailed clustering visualization. **Warning: This can be slow for large datasets!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set to True to run t-SNE (can be slow!)\n",
    "RUN_TSNE = False\n",
    "\n",
    "if RUN_TSNE:\n",
    "    fig, axes = plt.subplots(1, n_checkpoints, figsize=(5*n_checkpoints, 5))\n",
    "    \n",
    "    if n_checkpoints == 1:\n",
    "        axes = [axes]\n",
    "    \n",
    "    for idx, (checkpoint_name, data) in enumerate(all_checkpoint_embeddings.items()):\n",
    "        ax = axes[idx]\n",
    "        \n",
    "        embeddings = data['embeddings']\n",
    "        labels = data['labels']\n",
    "        \n",
    "        print(f\"Running t-SNE for {checkpoint_name}...\")\n",
    "        \n",
    "        # Apply t-SNE\n",
    "        tsne = TSNE(n_components=2, perplexity=30, n_iter=1000, random_state=42, verbose=1)\n",
    "        embeddings_2d = tsne.fit_transform(embeddings)\n",
    "        \n",
    "        # Plot\n",
    "        unique_labels = sorted(list(set(labels)))\n",
    "        colors = plt.cm.tab10(np.linspace(0, 1, len(unique_labels)))\n",
    "        \n",
    "        for label_idx, label in enumerate(unique_labels):\n",
    "            mask = np.array(labels) == label\n",
    "            ax.scatter(\n",
    "                embeddings_2d[mask, 0],\n",
    "                embeddings_2d[mask, 1],\n",
    "                c=[colors[label_idx]],\n",
    "                label=label,\n",
    "                alpha=0.6,\n",
    "                s=30,\n",
    "                edgecolors='black',\n",
    "                linewidth=0.5,\n",
    "            )\n",
    "        \n",
    "        ax.set_xlabel('t-SNE Component 1')\n",
    "        ax.set_ylabel('t-SNE Component 2')\n",
    "        ax.set_title(f'{checkpoint_name}\\n(768-dim embeddings)', fontweight='bold')\n",
    "        ax.legend(loc='best', fontsize=8)\n",
    "        ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    save_path = OUTPUT_DIR / 'tsne_comparison_all_checkpoints.png'\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    print(f\"Saved t-SNE comparison to: {save_path}\")\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"t-SNE visualization skipped. Set RUN_TSNE = True to enable.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pairwise Embedding Space Comparison\n",
    "\n",
    "Compute cosine similarity between the same samples across different checkpoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "if len(all_checkpoint_embeddings) >= 2:\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"PAIRWISE CHECKPOINT COMPARISON\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    checkpoint_names = list(all_checkpoint_embeddings.keys())\n",
    "    \n",
    "    # Create similarity matrix\n",
    "    n = len(checkpoint_names)\n",
    "    similarity_matrix = np.zeros((n, n))\n",
    "    \n",
    "    for i, name_i in enumerate(checkpoint_names):\n",
    "        emb_i = all_checkpoint_embeddings[name_i]['embeddings']\n",
    "        \n",
    "        for j, name_j in enumerate(checkpoint_names):\n",
    "            emb_j = all_checkpoint_embeddings[name_j]['embeddings']\n",
    "            \n",
    "            # Compute average cosine similarity between corresponding samples\n",
    "            # (assuming same order since we use same validation set)\n",
    "            cos_sim = np.mean([cosine_similarity(emb_i[k:k+1], emb_j[k:k+1])[0, 0] \n",
    "                               for k in range(len(emb_i))])\n",
    "            similarity_matrix[i, j] = cos_sim\n",
    "    \n",
    "    # Plot heatmap\n",
    "    fig, ax = plt.subplots(figsize=(8, 7))\n",
    "    \n",
    "    im = ax.imshow(similarity_matrix, cmap='RdYlGn', vmin=0, vmax=1, aspect='auto')\n",
    "    \n",
    "    # Set ticks\n",
    "    ax.set_xticks(np.arange(n))\n",
    "    ax.set_yticks(np.arange(n))\n",
    "    ax.set_xticklabels(checkpoint_names, rotation=45, ha='right')\n",
    "    ax.set_yticklabels(checkpoint_names)\n",
    "    \n",
    "    # Add colorbar\n",
    "    cbar = plt.colorbar(im, ax=ax)\n",
    "    cbar.set_label('Average Cosine Similarity', rotation=270, labelpad=20)\n",
    "    \n",
    "    # Add text annotations\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            value = similarity_matrix[i, j]\n",
    "            text_color = 'white' if value < 0.5 else 'black'\n",
    "            ax.text(j, i, f'{value:.3f}',\n",
    "                   ha=\"center\", va=\"center\", color=text_color, fontsize=10, weight='bold')\n",
    "    \n",
    "    ax.set_title('Pairwise Embedding Space Similarity\\n(Higher = More similar representations)', \n",
    "                 fontweight='bold', pad=20)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    save_path = OUTPUT_DIR / 'pairwise_similarity_matrix.png'\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    print(f\"\\nSaved similarity matrix to: {save_path}\")\n",
    "    plt.show()\n",
    "    \n",
    "    # Print numerical results\n",
    "    print(\"\\nPairwise Cosine Similarities:\")\n",
    "    for i in range(n):\n",
    "        for j in range(i+1, n):\n",
    "            print(f\"  {checkpoint_names[i]:20s} vs {checkpoint_names[j]:20s}: {similarity_matrix[i, j]:.4f}\")\n",
    "else:\n",
    "    print(\"Need at least 2 checkpoints for pairwise comparison\")"
   ]
  },
  {
   "cell_type": "code",
   "source": "if len(all_checkpoint_embeddings) >= 2 and 'df_patient' in locals():\n    # Create violin plots showing distribution of distances per checkpoint pair\n    fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n    \n    # Plot 1: Cosine Similarity Distribution\n    ax = axes[0]\n    checkpoint_pairs = df_patient['checkpoint_pair'].unique()\n    \n    violin_parts = ax.violinplot(\n        [df_patient[df_patient['checkpoint_pair'] == pair]['cosine_similarity'].values \n         for pair in checkpoint_pairs],\n        positions=range(len(checkpoint_pairs)),\n        showmeans=True,\n        showmedians=True,\n    )\n    \n    ax.set_xticks(range(len(checkpoint_pairs)))\n    ax.set_xticklabels(checkpoint_pairs, rotation=45, ha='right')\n    ax.set_ylabel('Cosine Similarity', fontweight='bold')\n    ax.set_title('Distribution of Per-Patient Cosine Similarity\\nAcross Checkpoint Pairs', \n                 fontweight='bold')\n    ax.grid(True, alpha=0.3, axis='y')\n    ax.set_ylim([0, 1])\n    \n    # Plot 2: L2 Distance Distribution\n    ax = axes[1]\n    \n    violin_parts = ax.violinplot(\n        [df_patient[df_patient['checkpoint_pair'] == pair]['l2_distance'].values \n         for pair in checkpoint_pairs],\n        positions=range(len(checkpoint_pairs)),\n        showmeans=True,\n        showmedians=True,\n    )\n    \n    ax.set_xticks(range(len(checkpoint_pairs)))\n    ax.set_xticklabels(checkpoint_pairs, rotation=45, ha='right')\n    ax.set_ylabel('L2 Distance', fontweight='bold')\n    ax.set_title('Distribution of Per-Patient L2 Distance\\nAcross Checkpoint Pairs', \n                 fontweight='bold')\n    ax.grid(True, alpha=0.3, axis='y')\n    \n    plt.tight_layout()\n    save_path = OUTPUT_DIR / 'per_patient_distance_distributions.png'\n    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n    print(f\"Saved distance distributions to: {save_path}\")\n    plt.show()\n    \n    # Print patients with highest/lowest embedding changes\n    print(\"\\n\" + \"=\"*80)\n    print(\"PATIENTS WITH LARGEST EMBEDDING CHANGES\")\n    print(\"=\"*80)\n    \n    for pair in checkpoint_pairs:\n        df_pair = df_patient[df_patient['checkpoint_pair'] == pair]\n        \n        print(f\"\\n{pair}:\")\n        \n        # Most different (lowest cosine similarity)\n        most_diff = df_pair.nsmallest(5, 'cosine_similarity')\n        print(\"  Most different embeddings (lowest cosine similarity):\")\n        for _, row in most_diff.iterrows():\n            print(f\"    Patient {row['patient_id']}: cos_sim={row['cosine_similarity']:.4f}, L2={row['l2_distance']:.4f}\")\n        \n        # Most similar (highest cosine similarity)\n        most_sim = df_pair.nlargest(5, 'cosine_similarity')\n        print(\"  Most similar embeddings (highest cosine similarity):\")\n        for _, row in most_sim.iterrows():\n            print(f\"    Patient {row['patient_id']}: cos_sim={row['cosine_similarity']:.4f}, L2={row['l2_distance']:.4f}\")\n    \n    print(\"\\n\" + \"=\"*80)\nelse:\n    print(\"Per-patient distance data not available for visualization\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### Distribution of Per-Patient Embedding Distances\n\nShow how embedding distances vary across patients for each checkpoint pair.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "if len(all_checkpoint_embeddings) >= 2:\n    checkpoint_names = list(all_checkpoint_embeddings.keys())\n    ref_checkpoint = checkpoint_names[0]\n    ref_patient_ids = all_checkpoint_embeddings[ref_checkpoint]['patient_ids']\n    \n    # Check if patient order is consistent\n    all_same = all(\n        all_checkpoint_embeddings[cp]['patient_ids'] == ref_patient_ids \n        for cp in checkpoint_names\n    )\n    \n    if all_same:\n        print(\"Visualizing patient trajectories across embedding spaces...\")\n        \n        # Concatenate all embeddings from all checkpoints for joint PCA\n        all_embs = np.vstack([\n            all_checkpoint_embeddings[cp]['embeddings'] \n            for cp in checkpoint_names\n        ])\n        \n        # Fit PCA on all embeddings together\n        pca = PCA(n_components=2, random_state=42)\n        all_embs_2d = pca.fit_transform(all_embs)\n        \n        # Split back into per-checkpoint embeddings\n        n_samples = len(ref_patient_ids)\n        checkpoint_embs_2d = {}\n        for i, cp in enumerate(checkpoint_names):\n            start_idx = i * n_samples\n            end_idx = (i + 1) * n_samples\n            checkpoint_embs_2d[cp] = all_embs_2d[start_idx:end_idx]\n        \n        # Select a few patients to visualize\n        unique_patients = sorted(list(set(ref_patient_ids)))\n        n_patients_to_show = min(10, len(unique_patients))\n        selected_patients = unique_patients[:n_patients_to_show]\n        \n        # Create visualization\n        fig, axes = plt.subplots(1, 2, figsize=(16, 7))\n        \n        # Plot 1: All patients with trajectories\n        ax = axes[0]\n        colors = plt.cm.tab20(np.linspace(0, 1, n_patients_to_show))\n        \n        for patient_idx, patient_id in enumerate(selected_patients):\n            # Get first occurrence index for this patient\n            idx = next(i for i, pid in enumerate(ref_patient_ids) if pid == patient_id)\n            \n            # Get embeddings for this patient across all checkpoints\n            patient_traj = []\n            for cp in checkpoint_names:\n                emb_2d = checkpoint_embs_2d[cp][idx]\n                patient_traj.append(emb_2d)\n            patient_traj = np.array(patient_traj)\n            \n            # Plot trajectory\n            ax.plot(\n                patient_traj[:, 0], \n                patient_traj[:, 1],\n                'o-',\n                color=colors[patient_idx],\n                label=f'Patient {patient_id}',\n                linewidth=2,\n                markersize=8,\n                alpha=0.7,\n            )\n            \n            # Add checkpoint labels\n            for i, cp_name in enumerate(checkpoint_names):\n                ax.annotate(\n                    cp_name[:3],  # Short label\n                    (patient_traj[i, 0], patient_traj[i, 1]),\n                    fontsize=6,\n                    ha='center',\n                    va='bottom',\n                )\n        \n        ax.set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]*100:.1f}%)', fontweight='bold')\n        ax.set_ylabel(f'PC2 ({pca.explained_variance_ratio_[1]*100:.1f}%)', fontweight='bold')\n        ax.set_title(\n            f'Patient Trajectories Across {len(checkpoint_names)} Checkpoints\\n'\n            f'(Showing {n_patients_to_show} patients)',\n            fontweight='bold'\n        )\n        ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=8)\n        ax.grid(True, alpha=0.3)\n        \n        # Plot 2: Checkpoint-colored view\n        ax = axes[1]\n        checkpoint_colors = plt.cm.Set1(np.linspace(0, 1, len(checkpoint_names)))\n        \n        for cp_idx, cp_name in enumerate(checkpoint_names):\n            embs_2d = checkpoint_embs_2d[cp_name]\n            ax.scatter(\n                embs_2d[:, 0],\n                embs_2d[:, 1],\n                c=[checkpoint_colors[cp_idx]],\n                label=cp_name,\n                alpha=0.5,\n                s=50,\n                edgecolors='black',\n                linewidth=0.5,\n            )\n        \n        ax.set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]*100:.1f}%)', fontweight='bold')\n        ax.set_ylabel(f'PC2 ({pca.explained_variance_ratio_[1]*100:.1f}%)', fontweight='bold')\n        ax.set_title(\n            'All Patients Colored by Checkpoint\\n'\n            '(Joint PCA projection)',\n            fontweight='bold'\n        )\n        ax.legend(loc='best', fontsize=10)\n        ax.grid(True, alpha=0.3)\n        \n        plt.tight_layout()\n        save_path = OUTPUT_DIR / 'patient_trajectories_across_checkpoints.png'\n        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n        print(f\"\\nSaved patient trajectories to: {save_path}\")\n        plt.show()\n        \n    else:\n        print(\"Cannot visualize trajectories - patient order differs between checkpoints\")\nelse:\n    print(\"Need at least 2 checkpoints for trajectory visualization\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### Visualization: Patient Trajectories Across Embedding Spaces\n\nVisualize how individual patients \"move\" in the embedding space across different checkpoints using PCA projection.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "if len(all_checkpoint_embeddings) >= 2:\n    print(\"\\n\" + \"=\"*80)\n    print(\"PER-PATIENT EMBEDDING DISTANCE ANALYSIS\")\n    print(\"=\"*80)\n    \n    checkpoint_names = list(all_checkpoint_embeddings.keys())\n    \n    # Get first checkpoint as reference for patient list\n    ref_checkpoint = checkpoint_names[0]\n    ref_patient_ids = all_checkpoint_embeddings[ref_checkpoint]['patient_ids']\n    \n    # Verify all checkpoints have same patients in same order\n    all_same = True\n    for cp_name in checkpoint_names[1:]:\n        cp_patient_ids = all_checkpoint_embeddings[cp_name]['patient_ids']\n        if cp_patient_ids != ref_patient_ids:\n            print(f\"WARNING: Patient order differs between {ref_checkpoint} and {cp_name}\")\n            all_same = False\n    \n    if all_same:\n        print(f\"\\nAll checkpoints have the same {len(ref_patient_ids)} patients in the same order.\")\n        print(\"Computing per-patient embedding distances across checkpoints...\\n\")\n        \n        # Compute per-patient cosine distances across all checkpoint pairs\n        unique_patients = sorted(list(set(ref_patient_ids)))\n        \n        # Create DataFrame to store results\n        per_patient_results = []\n        \n        for patient_id in unique_patients:\n            # Get indices for this patient across all checkpoints\n            patient_indices = [i for i, pid in enumerate(ref_patient_ids) if pid == patient_id]\n            \n            if len(patient_indices) == 0:\n                continue\n            \n            # For simplicity, take first session if patient has multiple\n            idx = patient_indices[0]\n            \n            # Compute pairwise distances for this patient across checkpoints\n            for i in range(len(checkpoint_names)):\n                for j in range(i+1, len(checkpoint_names)):\n                    cp_i = checkpoint_names[i]\n                    cp_j = checkpoint_names[j]\n                    \n                    emb_i = all_checkpoint_embeddings[cp_i]['embeddings'][idx]\n                    emb_j = all_checkpoint_embeddings[cp_j]['embeddings'][idx]\n                    \n                    # Compute cosine similarity\n                    cos_sim = cosine_similarity(emb_i.reshape(1, -1), emb_j.reshape(1, -1))[0, 0]\n                    # Compute L2 distance\n                    l2_dist = np.linalg.norm(emb_i - emb_j)\n                    \n                    per_patient_results.append({\n                        'patient_id': patient_id,\n                        'checkpoint_pair': f'{cp_i} vs {cp_j}',\n                        'cosine_similarity': cos_sim,\n                        'l2_distance': l2_dist,\n                    })\n        \n        # Create DataFrame\n        df_patient = pd.DataFrame(per_patient_results)\n        \n        # Summary statistics\n        print(\"Average embedding distances per checkpoint pair:\")\n        print(\"-\" * 80)\n        for pair in df_patient['checkpoint_pair'].unique():\n            df_pair = df_patient[df_patient['checkpoint_pair'] == pair]\n            avg_cos = df_pair['cosine_similarity'].mean()\n            std_cos = df_pair['cosine_similarity'].std()\n            avg_l2 = df_pair['l2_distance'].mean()\n            std_l2 = df_pair['l2_distance'].std()\n            print(f\"{pair:40s}\")\n            print(f\"  Cosine Similarity: {avg_cos:.4f} ± {std_cos:.4f}\")\n            print(f\"  L2 Distance:       {avg_l2:.4f} ± {std_l2:.4f}\")\n            print()\n        \n        # Save per-patient results\n        df_patient.to_csv(OUTPUT_DIR / 'per_patient_distances.csv', index=False)\n        print(f\"Saved per-patient distances to: {OUTPUT_DIR / 'per_patient_distances.csv'}\")\n        \n    else:\n        print(\"Cannot perform per-patient analysis - patient order differs between checkpoints\")\nelse:\n    print(\"Need at least 2 checkpoints for per-patient comparison\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Per-Patient Analysis Across Checkpoints\n\nAnalyze how **the same patient** is embedded differently across the 4 checkpoints.",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "Now that you have the 768-dim embeddings extracted from all 4 checkpoints, you can:\n",
    "\n",
    "1. **Further Analysis**:\n",
    "   - Cluster analysis (k-means, hierarchical clustering)\n",
    "   - Linear probing evaluation\n",
    "   - Representation quality metrics (silhouette score, etc.)\n",
    "   \n",
    "2. **Visualization**:\n",
    "   - UMAP visualization (alternative to t-SNE)\n",
    "   - Per-class embedding distributions\n",
    "   - Attention maps visualization\n",
    "   \n",
    "3. **Comparison Metrics**:\n",
    "   - CKA (Centered Kernel Alignment) between checkpoints\n",
    "   - Representation stability analysis\n",
    "   - Downstream task performance correlation\n",
    "\n",
    "All embeddings are saved in: `{OUTPUT_DIR}`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}